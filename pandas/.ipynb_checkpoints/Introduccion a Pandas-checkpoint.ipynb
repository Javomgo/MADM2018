{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "### Índice\n",
    "   1. [Carga de datos](#carga)\n",
    "   \n",
    "   2. [Indexación](#index)\n",
    "   \n",
    "   3. [Filtrado](#filter)\n",
    "   \n",
    "   4. [Unión](#union)\n",
    "   \n",
    "   5. [Agregación](#agg)\n",
    "   \n",
    "   6. [Información faltante](#NA)\n",
    "   \n",
    "   7. [Extra](#extra) : Funciones, TimeStamps, Pivotes, HTML\n",
    "\n",
    "Pandas es la solución que Python propone frente a R. Es una buena tecnología para tratar conjuntos de datos \"pequeños\", \n",
    "es decir, aquellos que caben en la memória RAM del ordenador.\n",
    "\n",
    "El concepto básico que introduce pandas es el de **data frame**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos básicos de Pandas\n",
    "\n",
    "### Data Frames\n",
    "\n",
    "Como una tabla, con filas y columnas (por ejemplo, como en SQL). \n",
    "Excepto:\n",
    "   - Las filas pueden ser indexadas por algo interesante (hay soporte especial para etiquetas como datos categóricos y de series temporales). Esto es especialmente útil cuando tiene datos de series temporales con puntos de datos potencialmente faltantes.\n",
    "   - Las celdas pueden almacenar objetos de Python. Al igual que en un excel, las columnas son homogéneas.\n",
    "   - En lugar de \"NULL\", el nombre para un valor inexistente es \"NA\". A diferencia de R, los dataframes de Python solo admiten NA en columnas de algunos tipos de datos (básicamente: números en coma flotante y 'objetos'), pero esto no es un problema en su mayor parte.\n",
    "  \n",
    "### Serie de datos:\n",
    "\n",
    "Estas son las columnas de un DataFrame (más correctamente, un dataframe es un diccionario de Series). Las observaciones de la serie tienen un tipo homogéneo.\n",
    "\n",
    "<img src=\"img/4-pandas/Data_Frame_Data_Series.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number animal\n",
       "0       1    cat\n",
       "1       2    dog\n",
       "2       3  mouse"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import re # expresiones regulares\n",
    "\n",
    "# un data frame\n",
    "df1 = pd.DataFrame({\n",
    "    'number': [1, 2, 3],\n",
    "    'animal': ['cat', 'dog', 'mouse']\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      cat\n",
       "1      dog\n",
       "2    mouse\n",
       "Name: animal, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seleccionamos la columna animal\n",
    "df1['animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos los tipos de datos de las columnas\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['number'] = df1['number'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe igual\n",
    "df2 = pd.DataFrame([\n",
    "    (1.0, 'cat'),\n",
    "    (2.0, 'dog'),\n",
    "    (3.0, 'mouse'),\n",
    "], columns=['number', 'animal'])\n",
    "\n",
    "np.all(df1 == df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbos (operaciones) en Pandas\n",
    "  \n",
    "Pandas proporciona un análisis básico de datos \"con pilas incluidas\":\n",
    "  - ** Cargando datos: ** `read_csv`,` read_table`, `read_sql`, y ` read_html`\n",
    "  - ** Selección, filtrado y agregación ** (es decir, operaciones de tipo SQL): hay una sintaxis especial para seleccionar. Existe el método `merge`. También hay una sintaxis fácil para crear una columna nueva cuyo valor se calcula desde otra columna, con la ventaja que los cálculos pueden usar toda la potencia de Python (aunque podría ser más rápido si no lo hiciera ;) ).\n",
    "  - ** NA handling: ** Al igual que los dataframes de R, hay un buen soporte para transformar los valores de NA con valores por defecto / trucos de promedios / etc.\n",
    "  - ** Estadísticas básicas: ** `mean`, ` median`, `max`,` min`, y el siempre útil `describe`.\n",
    "  - ** Conectando a análisis más avanzados: ** Esto no se incluye por defecto. Pero aún así, se entiende razonablemente bien con `sklearn`.\n",
    "  - ** Visualización: ** Por ejemplo `plot` y `hist`. Tambien podemos usar matplotlib y también seaborn.\n",
    "  \n",
    "Examinaremos un poco sobre todos estos en el contexto de un ejemplo.\n",
    "\n",
    "Vamos a explorar un conjunto de datos de seguro hipotecario emitido por la Autoridad Federal de Vivienda (FHA). Los datos se desglosan por tramo censal y nos dice qué tamaño tiene la FHA en cada tramo (cuántas casas, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"carga\"></a> Carga de datos y primera toma de contacto \n",
    "\n",
    "**Podemos leer un csv y decirle que nombre tiene cada columna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>103.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>603.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "0         8.0         75.0                  NaN        1        1   \n",
       "1        28.0         49.0               103.01        1        1   \n",
       "2        40.0          3.0                  NaN        1        1   \n",
       "3        39.0        113.0               603.00        3        3   \n",
       "4        12.0        105.0               124.04        2        2   \n",
       "\n",
       "   PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA  \n",
       "0        100.0      258      258        100.0  \n",
       "1        100.0       71       71        100.0  \n",
       "2        100.0      215      215        100.0  \n",
       "3        100.0      206      206        100.0  \n",
       "4        100.0      303      303        100.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names =[\"State_Code\", \"County_Code\", \"Census_Tract_Number\",\n",
    "        \"NUM_ALL\", \"NUM_FHA\", \"PCT_NUM_FHA\", \"AMT_ALL\",\n",
    "        \"AMT_FHA\", \"PCT_AMT_FHA\"]\n",
    "\n",
    "df = pd.read_csv('fha_by_tract.csv', names=names)  # Cargamos un archivo csv\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O también asignar los nombres a las columnas a posteriori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names =[\"StateCode\", \"County_Code\", \"Census_Tract_Number\",\n",
    "        \"NUM_ALL\", \"NUM_FHA\", \"PCT_NUM_FHA\", \"AMT_ALL\",\n",
    "        \"AMT_FHA\", \"PCT_AMT_FHA\"]\n",
    "\n",
    "df.columns = names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={\"StateCode\":\"State_Code\"}) # incluso lo podemos hacer una columna en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #Probad de pasar un número por parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crear una nueva columna como combinación de otras:** 'Census_Tract_Number', 'County_Code' y 'State_Code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>103.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.804901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>603.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.911306e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.210501e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "0         8.0         75.0                  NaN        1        1   \n",
       "1        28.0         49.0               103.01        1        1   \n",
       "2        40.0          3.0                  NaN        1        1   \n",
       "3        39.0        113.0               603.00        3        3   \n",
       "4        12.0        105.0               124.04        2        2   \n",
       "\n",
       "   PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  \n",
       "0        100.0      258      258        100.0           NaN  \n",
       "1        100.0       71       71        100.0  2.804901e+10  \n",
       "2        100.0      215      215        100.0           NaN  \n",
       "3        100.0      206      206        100.0  3.911306e+10  \n",
       "4        100.0      303      303        100.0  1.210501e+10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GEOID'] = df['Census_Tract_Number']*100 + 10**6 * df['County_Code'] + 10**9 * df['State_Code']   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos eliminar una columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>103.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>603.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>124.04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "0         8.0         75.0                  NaN        1        1   \n",
       "1        28.0         49.0               103.01        1        1   \n",
       "2        40.0          3.0                  NaN        1        1   \n",
       "3        39.0        113.0               603.00        3        3   \n",
       "4        12.0        105.0               124.04        2        2   \n",
       "\n",
       "   PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA  \n",
       "0        100.0      258      258        100.0  \n",
       "1        100.0       71       71        100.0  \n",
       "2        100.0      215      215        100.0  \n",
       "3        100.0      206      206        100.0  \n",
       "4        100.0      303      303        100.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_drop = 'GEOID'\n",
    "df.drop(column_to_drop, axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de las operaciones producen copias (a menos que se especifique `inplace = True`). El objeto `df` todavía tiene la columna GEOID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miramos si la columna aún esta en el dataframe\n",
    "column_to_drop in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Usar inplace=True no es recomendable, es mejor asignar el nuevo dataframe a una nueva variable.\n",
    "\n",
    "df_new = df.drop(column_to_drop, axis = 1)\n",
    "\n",
    "print(column_to_drop in df.columns)\n",
    "\n",
    "print(column_to_drop in df_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las filas también se pueden eliminar. Los índices no se reinician. El índice está asociado con la fila, no con el orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(0, axis=0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, las filas están indexadas por su posición. Sin embargo, cualquier columna se puede convertir en un índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('State_Code').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos indexar a multiples niveles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index(['State_Code', 'County_Code']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos volver atrás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('State_Code').reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos describir una columna\n",
    "print(\"Percentage of mortages in each census tract insured by FHA\")\n",
    "df['PCT_AMT_FHA'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O el dataframe entero\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar el histograma de una columna.\n",
    "df['PCT_AMT_FHA'].plot(kind='hist', bins=100);#Probad a poner y quitar el ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"index\"></a> Indexando un dataframe\n",
    "\n",
    "Indexar por un nombre de columna produce una serie de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State_Code'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexar por una lista de nombres de columna da otro dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['State_Code', 'County_Code']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** Que nos devolverá?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[['State_Code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['State_Code']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un dataframe es un iterador que nos devuelve el nombre de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State_Code\n",
      "County_Code\n",
      "Census_Tract_Number\n",
      "NUM_ALL\n",
      "NUM_FHA\n",
      "PCT_NUM_FHA\n",
      "AMT_ALL\n",
      "AMT_FHA\n",
      "PCT_AMT_FHA\n",
      "GEOID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['State_Code',\n",
       " 'County_Code',\n",
       " 'Census_Tract_Number',\n",
       " 'NUM_ALL',\n",
       " 'NUM_FHA',\n",
       " 'PCT_NUM_FHA',\n",
       " 'AMT_ALL',\n",
       " 'AMT_FHA',\n",
       " 'PCT_AMT_FHA',\n",
       " 'GEOID']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col)\n",
    "\n",
    "# De forma avanzada, generamos una lista de columnas\n",
    "[col for col in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos visto como seleccionar columnas, pero no hemos visto como seleccionar filas de nuestro conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>103.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.804901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "0         8.0         75.0                  NaN        1        1   \n",
       "1        28.0         49.0               103.01        1        1   \n",
       "2        40.0          3.0                  NaN        1        1   \n",
       "\n",
       "   PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  \n",
       "0        100.0      258      258        100.0           NaN  \n",
       "1        100.0       71       71        100.0  2.804901e+10  \n",
       "2        100.0      215      215        100.0           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para indexar un elemento particular del dataframe, usaremos el atributo `.loc`.  Que toma como parámetroíndice y columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>103.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.804901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>9502.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.806395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.804900e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.815100e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.815100e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.804900e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>103.0</td>\n",
       "      <td>9502.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.810395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>2.804900e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>7.01</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>84.2105</td>\n",
       "      <td>1365</td>\n",
       "      <td>1244</td>\n",
       "      <td>91.1355</td>\n",
       "      <td>2.815100e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  PCT_NUM_FHA  \\\n",
       "State_Code                                                                    \n",
       "28.0               49.0               103.01        1        1     100.0000   \n",
       "28.0               77.0                  NaN        1        1     100.0000   \n",
       "28.0               63.0              9502.00        1        1     100.0000   \n",
       "28.0               49.0                25.00        1        1     100.0000   \n",
       "28.0              151.0                12.00        3        3     100.0000   \n",
       "28.0              151.0                21.00        2        2     100.0000   \n",
       "28.0               49.0                22.00        1        1     100.0000   \n",
       "28.0              103.0              9502.00        1        1     100.0000   \n",
       "28.0               49.0                27.00        1        1     100.0000   \n",
       "28.0              151.0                 7.01       19       16      84.2105   \n",
       "\n",
       "            AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  \n",
       "State_Code                                               \n",
       "28.0             71       71     100.0000  2.804901e+10  \n",
       "28.0            177      177     100.0000           NaN  \n",
       "28.0            133      133     100.0000  2.806395e+10  \n",
       "28.0             82       82     100.0000  2.804900e+10  \n",
       "28.0            118      118     100.0000  2.815100e+10  \n",
       "28.0            107      107     100.0000  2.815100e+10  \n",
       "28.0             39       39     100.0000  2.804900e+10  \n",
       "28.0            165      165     100.0000  2.810395e+10  \n",
       "28.0             78       78     100.0000  2.804900e+10  \n",
       "28.0           1365     1244      91.1355  2.815100e+10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxf = df.set_index('State_Code')\n",
    "auxf.loc[28.0,:].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3, 'State_Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inusualmente para Python, ambos puntos finales se incluyen en el sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:3, ['State_Code','Census_Tract_Number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La indexación basada en la posición se realiza con el atributo `.iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convención de corte habitual se utiliza para `.iloc`. Es decir, el extremo superior no se incluye en el segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"filter\"></a>  Filtrado de información\n",
    "\n",
    " La notación `df [...]` es muy flexible:\n",
    "   - Acepta nombres de columnas (cadenas y listas de cadenas);\n",
    "   - Acepta los números de las columnas (siempre que no haya ambigüedad con los nombres de las columnas);\n",
    "   - ¡Acepta series de datos binarias! \n",
    "  \n",
    "Esto significa que puedes escribir:\n",
    "```python\n",
    "\n",
    " df[ df['column_name2'] == 'MD' & ( df['column_name1']==5 | df['column_name1']==6 ) ]\n",
    "```   \n",
    "para los que sepan SQL seria una cosa muy similar a:\n",
    "```sql\n",
    "SELECT * FROM df\n",
    "WHERE column_name2=\"MD\" AND (column_name1=5 OR column_name1=6)\n",
    "```           \n",
    "Los operadores booleanos en un dataframe devuelven una serie de datos de bools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['State_Code'] == 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos se pueden combinar con los operadores booleanos (a nivel de bit). Tened en cuenta que, debido a la precedencia del operador, es mejor poner las comparaciones individuales entre paréntesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df['State_Code'] == 1) & (df['Census_Tract_Number'] == 9613)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dataframes pueden ser indexados por series de booleanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['State_Code'] == 5][['State_Code', 'County_Code']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nota: ** selecciona filas por series de datos binarios solo si comparten el mismo índice de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"union\"></a> Uniendo datos (joining)\n",
    "\n",
    "Lo análogo a\n",
    ">             \n",
    "    SELECT * \n",
    "        FROM df1\n",
    "        INNER JOIN df2 \n",
    "        ON df1.field_name=df2.field_name;\n",
    "\n",
    "es\n",
    "\n",
    "    df_joined = df1.merge(df2, on='field_name')\n",
    "\n",
    "También  se pueden hacer joins izquierda / derecha, mezclar y combinar nombres de columna, etc. [Documentación Pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html)\n",
    "\n",
    "Vamos a realizar la unión de dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first row is the column names, so we don't have to specify those\n",
    "df_geo = pd.read_csv('2013_Gaz_tracts_national.tsv', sep='\\t')\n",
    "df_geo.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df.merge(df_geo, on=\"GEOID\", how='left')\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"agg\"></a>  Agregando información\n",
    "\n",
    "El análogo al SQL `GROUP BY` es\n",
    "\n",
    "    grouped = df.groupby(['field_name1', ...])...\n",
    "\n",
    "En SQL seria\n",
    "\n",
    ">   SELECT mean(df.value1), std(df.value2) \n",
    "        FROM df\n",
    "        GROUP BY df.field_name1, ...\n",
    "\n",
    "Pandas es algo más flexible en cuanto a cómo agrupar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_groups = df_joined.groupby('USPS')\n",
    "usps_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón por la que Pandas no requiere que especifiques una función de agregación por adelantado es porque el método groupby por sí solo ya realiza parte del trabajo. Devuelve un tipo de datos `DataFrameGroupBy` que contiene un diccionario de claves de grupo para las listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(usps_groups.groups))\n",
    "usps_groups.groups['MS'][:5] # Vemos los 5 primeros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_groups.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos recuperar el grupo de datos asociados con una clave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_groups.get_group('AK')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es lo mismo que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.iloc[usps_groups.groups['AK'][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_groups.mean().head()  #Proporciona la media de cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_by_state = df_joined.groupby('USPS').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_by_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes especificar una función de agregación para cada columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_groups['NUM_FHA', 'NUM_ALL'].agg({'NUM_FHA': np.sum, 'NUM_ALL': np.mean}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **groupby** es especialmente útil cuando definimos nuestras propias funciones de agregación. Aquí, definimos una función que devuelve la fila para la pista del censo ubicada más al norte. La función de aplicar intenta 'combinar resultados de una manera inteligente'. La lista de objetos Serie de cada llamada a `farthest_north` para cada código USPS se contrae en una sola tabla DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_north(state_df):\n",
    "    # descending sort, then select row 0\n",
    "    # the datatype will be a pandas Series\n",
    "    return state_df.sort_values('INTPTLAT', ascending=False).iloc[0]\n",
    "\n",
    "df_joined.groupby('USPS').apply(farthest_north)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenando por índices y columnas\n",
    "\n",
    "Podemos ordenar nuestro dataframe en base al índice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_state.sort_index(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ordenar según el valor de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_state.sort_values('AMT_FHA', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores únicos\n",
    "\n",
    "\n",
    "En Pandas podemos contar el número de valores únicos, repeticiones i testear la pertenencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State_Code'].unique() #[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df['State_Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['State_Code'].isin(df['State_Code'].head(3))].head() #Seleccionamos según la pertenencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"NA\"></a>  Tratamiento de información faltante y NA\n",
    "\n",
    "Cuando leemos un  archivo CSV o una base de datos SQL, a menudo encontramos valores \"NA\" (o \"nulo\", \"Ninguno\", etc.). El lector CSV tiene un campo especial para especificar cómo se denota esto, y SQL tiene la noción incorporada de NULL. Pandas proporciona algunas herramientas para trabajar con estos; generalmente son similares a (y un poco peor que) `R`.\n",
    "\n",
    "Debemos tener en cuenta que estos métodos no lo hacen ´inplace´, es decir, crean una nueva serie y no cambian la original.\n",
    "\n",
    "[Mas detalles](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GEOID'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.isnull()` y `.notnull()` examinan si existe algún null y devuelven una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GEOID'].isnull()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.dropna()`  elimina las filas con información nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos el número de observaciones con NA y el número de observaciones una vez eliminamos los NA\n",
    "print(df['GEOID'].size, df['GEOID'].dropna().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fillna()` substituye los valores N/A con otro valor.  `.interpolate()` substituye los valores nulos con una interpolación (linear, or quadratic, or...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fill_0'] = df['GEOID'].fillna(0)                          # Fills constant value, here 0\n",
    "df['fill_forward'] = df['GEOID'].fillna(method='ffill')       # Fill forwards\n",
    "df['fill_back'] = df['GEOID'].fillna(method='bfill', limit=5) # Fill backwards, at most 5\n",
    "df['fill_mean'] = df['GEOID'].fillna(df['GEOID'].mean())      # Fills constant value, here the mean (imputation)\n",
    "df['fill_interp'] = df['GEOID'].interpolate()                 # Fills interpolated value\n",
    "df[['GEOID', 'fill_0', 'fill_forward', 'fill_back', 'fill_mean', 'fill_interp']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nota\n",
    "Los valores N / A (generalmente) se ignoran inteligentemente al realizar otros cálculos en dataframes. Por ejemplo, cuando se usan métodos de cadena en series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_series = df['GEOID'].replace(0, np.nan).apply(str)\n",
    "print(text_series[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_series[:10].str.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aplicación de la media en los datos numéricos ignora los NA por defecto (consultar la documentación):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['GEOID'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = df_joined['USPS'].dropna()\n",
    "states[states.str.contains('A')].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"extra\"></a>  EXTRA!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices en Pandas\n",
    "\n",
    "Los índices de pandas nos permiten manejar los datos de forma natural. ** Como hemos comentado antes, los elementos se asocian en función de su índice, no de su orden. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2,3], index=['a', 'b', 'c'])\n",
    "s2 = pd.Series([3,2,1], index=['c', 'b', 'a'])\n",
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = pd.Series([3,2,1], index=['c', 'd', 'e'])\n",
    "s1 + s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores faltantes obtienen un NaN, pero esto puede ser reemplazado por un valor de relleno de nuestra elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.add(s3, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando funciones\n",
    "\n",
    "Para la aplicación de funciones a nivel de elemento, lo más sencillo es aplicar funciones **numpy** a estos objetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(24).reshape(4,6))\n",
    "\n",
    "np.sin(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se basa en funciones numpy que se transmiten automáticamente para trabajar en función de los elementos. Para aplicar una función Python a cada elemento, use el método `.applymap ()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.applymap(lambda x: \"%.2f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, a veces desea calcular cosas en columnas o filas. En este caso, deberá usar el método `apply`.\n",
    "\n",
    "Por ejemplo, el siguiente código muestra el rango de valores de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando análisis más avanzados\n",
    "\n",
    "Casi cualquier herramienta de \"análisis avanzado\" en el ecosistema de Python va a tomar matrices de tipo `np.array` como entrada. Puede acceder a la matriz subyacente de una columna de un data frame como\n",
    "\n",
    "         df ['column']. values\n",
    "        \n",
    "Muchos de ellos toman `nd.array` a cuyos datos subyacentes se puede acceder mediante\n",
    "\n",
    "         df.values\n",
    "        \n",
    "directamente. * La mayoría * de las veces, tomarán `df ['column']` y `df` sin necesidad de mirar los valores.\n",
    "\n",
    "Esto es particularmente importante si desea usar Pandas con la biblioteca sklearn. Consultad esta [publicación](http://www.markhneedham.com/blog/2013/11/09/python-making-scikit-learn-and-pandas-play-nice/) para ver un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: x.max() - x.min(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Timestamps\n",
    "\n",
    "Pandas viene con excelentes herramientas para administrar datos temporales. El elemento central de esto es la clase Timestamp, que puede inferir marcas de tiempo de muchas entradas diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pd.Timestamp('July 4, 2016'))\n",
    "print(pd.Timestamp('Monday, July 4, 2016'))\n",
    "print(pd.Timestamp('Tuesday, July 4th, 2016'))  # notice it ignored 'Tuesday'\n",
    "print(pd.Timestamp('Monday, July 4th, 2016 05:00 PM'))\n",
    "print(pd.Timestamp('04/07/2016T17:20:13.123456'))\n",
    "print(pd.Timestamp(1467651600000000000))  # number of ns since the epoch, 1/1/1970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien con zonas horarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "july4 = pd.Timestamp('Monday, July 4th, 2016 05:00 PM').tz_localize('US/Eastern')\n",
    "labor_day = pd.Timestamp('9/5/2016 12:00', tz='US/Eastern')\n",
    "thanksgiving = pd.Timestamp('11/24/2016 16:00')  # no timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas puede hacer cálculos en Timestamps si están localizados en la misma zona horaria o ninguno tiene una zona horaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(labor_day - july4)\n",
    "# con  thanksgiving - july4  # obtendriamos un error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los desplazamientos de series de tiempo son útiles para calcular fechas relativas a otra fecha. Observad que omite durante los días de fin de semana, pero es ajeno a las vacaciones. Pandas admite [calendarios personalizados] (http://pandas.pydata.org/pandas-docs/stable/timeseries.html#holidays-holiday-calendars) si los necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import BDay, Day, BMonthEnd\n",
    "\n",
    "print(july4 + Day(5))  # 5 calendar days later, a Saturday.\n",
    "print(july4 + BDay(5))  # 5 business days later, or the following Monday.\n",
    "print(july4 - BDay(1))  # 1 business day earlier, or the previous Friday.\n",
    "print(july4 + BMonthEnd(1))  # last business day of the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas puede generar rangos de fechas. Aquí generamos una lista de los días de trabajo de enero de 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_days = pd.date_range('1/1/2016', '1/31/2016', freq='B')\n",
    "business_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto a su vez puede usarse como un índice de DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(np.random.rand(len(business_days)),\n",
    "                    index=business_days,\n",
    "                   columns=['random'])\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones de zona horaria siguen siendo usables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_df.tz_localize('UTC').tz_convert('US/Pacific').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-indices, stacking, and pivot tables\n",
    "\n",
    "Data frames pueden contener múltiples índices para filas o columnas. Por ejemplo, la agrupación por dos columnas producirá un índice de fila de dos niveles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['State_Code', 'County_Code'])[['NUM_ALL', 'NUM_FHA']].sum()\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un índice de fila pues ser transformado a un índice de columna con el método `.unstack()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped.unstack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.stack()` realiza el trabajo contrario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.all(grouped.unstack().stack() == grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto puede llevarse a cabo con la función `pivot_table()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, index='State_Code', columns='County_Code',\n",
    "               values=['NUM_ALL', 'NUM_FHA'], aggfunc=np.sum).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may already by familiar with pivot tables in Excel.  These work similarly, and area  good tool for changing the dependent and independent variables for aggregations of data. See http://pandas.pydata.org/pandas-docs/stable/reshaping.html for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas HTML data import example\n",
    "\n",
    "Pandas takes a \"batteries included\" approach and throws in a whole lot of convenience functions.  For instance it has import functions for a variety of formats.  One of the pleasant surprises is a command `read_html` that's meant to automate the process of extracting tabular data from HTML.  In particular, it works pretty well with tables on Wikipedia.  \n",
    "\n",
    "Let's do an example: We'll try to extract the list of the world's tallest structures from\n",
    "http://en.wikipedia.org/wiki/List_of_tallest_buildings_and_structures_in_the_world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_html('http://en.wikipedia.org/wiki/List_of_tallest_buildings_and_structures_in_the_world', header=0, parse_dates=False)\n",
    "\n",
    "# There are several tables on the page.  By inspection we can figure out which one we want\n",
    "tallest = dfs[3]\n",
    "print(tallest.columns)\n",
    "# The coordinates column needs to be fixed up.  This is a bit of string parsing:\n",
    "def clean_lat_long(s):\n",
    "    try:\n",
    "        parts = s.split(\"/\")\n",
    "    except AttributeError:\n",
    "        return (None, None)\n",
    "    if len(parts) < 3:\n",
    "        return (None, None)\n",
    "    m = re.search(r\"(\\d+[.]\\d+);[^\\d]*(\\d+[.]\\d+)[^\\d]\", parts[2])\n",
    "    if not m:\n",
    "        return (None, None)\n",
    "    return (m.group(1), m.group(2))\n",
    "\n",
    "tallest['Clean_Coordinates'] = tallest['Coordinates'].apply(clean_lat_long)\n",
    "tallest['Latitude'] = tallest['Clean_Coordinates'].apply(lambda x:x[0])\n",
    "tallest['Longitude'] = tallest['Clean_Coordinates'].apply(lambda x:x[1])\n",
    "\n",
    "# Et voila\n",
    "tallest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "1. Parse the table rankings of [UK universities available on Wikipedia](https://en.wikipedia.org/wiki/Rankings_of_universities_in_the_United_Kingdom):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
